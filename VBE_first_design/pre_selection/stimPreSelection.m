%% STIMULI SELECTION FROM LEXIQUE 3.83 AND LEXIQUE INFRA 1.11
% Date of creation: 24/12/2020
% by Filippo Cerpelloni
% 
% For the experiment, a selection of french words is o be performed.
% Such words must have some constraints: 
% - french words
% - length of 6 letters
% - coming from 2 categories: Animate (ANIMALS) and Inanimate (PLACES)
% 
% From Lexique, we must extract those words who fit this constraints.
% 
% TO ADD: download of both Lexique and Infra
%         selection of words for pilot+mvpa: also 5 ad 7 letters long.
%           Maybe better sets?
%          
% RUN BLOCK PER BLOCK, NOT ALL TOGETHER
error('RUN ONE BLOCK AFTER THE OTHER! DON''T MAKE ME REPEAT THAT');

%% 1. Open and import lexique (xls file) into a MATLAB table
%  Later, add code to download it directly
clear;

addpath('Lexique383');
addpath('LexiqueInfra111');
importLex; % script generated by MATLAB. Selection of relevant fields is in the import_lex.m script
importInfra; % same goes of Infra

%% 2. Selection of relevant words

% High frequency first, sorts by the most frequent (both films and books).
% Films before books as they have the biggest corpus of words (50 mil v.
% 14.7 mil)
lex = sortrows(lex,{'freqfilms2','freqlivres'},'descend');
lex_length = size(lex,1);

% Position in the orginial frequency order
lex.freq_pos = [1:lex_length]';

% First selection: keep only those words wtih 1/million frequency in AT LEAST one of the
% indexes
lex = lex(lex.freqfilms2 > 1 | lex.freqlivres > 1,:);

% SELECTION FOR LOCALIZER
loc_lex = lex(lex.cgram == 'NOM' & lex.nblettres >= 4 & lex.nblettres <= 8,:); % names

% SELECTION FOR MVPA AND PILOT
mvpa_6L_lex = lex(lex.cgram == 'NOM' & lex.nblettres == 6 & lex.nombre == 's',:); % names

%% 3. Translation of words FR to EN (to comprehend what to choose) -6L
% Take words that have enough frequency (higher than 1 per million) 
% in either index.
% 
% Those are translated manually (can be partially improved) with 
% GOOGLE TRANSLATE: web('https://translate.google.com/#fr/en/');
%
% Manual index of letters will be in aide.txt
% Words selected are then assigned to the corresponding array (animal / place) with their translation
%
% Words will be cross-checked with french speakers (not scriptable,
% obviously)

% Places selection - manual, made looking at translations 
places = mvpa_6L_lex([3 18 20 55 56 67 71 81 161 172 182 199 222 227 237 240 250 253 ...
                     254 268 283 309 329 343 362 400 404 450 464 523 525 535 549 558 564 567 568 590 ...
                     624 668 732 774 796 888 969 980 996 1034 1056 1190 1194 1285 1291 1348 1392],:);

places.transl = {'house' 'office' 'jail' 'bank' 'class' 'cinema' 'church' 'garden' 'desert' 'garage' ...
             'circus' 'river' 'cabin' 'apartment' 'jungle' 'tunnel' 'mountain peak' 'temple' 'hut' ...
             'town hall' 'valley' 'casino' 'balcony' 'cave' 'avenue' 'barn' 'mill' 'status' 'hangar' ...
             'palace' 'volcano' 'shore' 'canyon' 'alley' 'sierra' 'chalet' 'bunker' 'abbey' 'restaurant' ...
             'dungeon' 'lagoon' 'valley' 'vault' 'steppe' 'kennel' 'porch' 'favela' 'marina' 'cove' 'bistro' ...
             'pine forest' 'savannah' 'fort' 'channel' 'castel'}';
places = movevars(places, 'transl', 'Before', 'phon');
         
% Of those which have at least one index over 1 per million, extract those
% which have BOTH (second option)
places_AND = places(places.freqfilms2 > 1 & places.freqlivres > 1,:);                 

% Animal selection - same process
animals = mvpa_6L_lex([47 108 143 190 236 246 275 350 358 365 434 443 471 499 516 555 563 579 613 618 621 ...
                     627 660 676 688 695 714 723 734 738 752 762 814 828 904 906 917 930 970 971 1002 1025 ...
                     1083 1129 1166 1274 1338 1366 1399 1473],:);
                 
% (manual; to improve one could take the output of the translation page)                 
animals.transl = {'horse' 'bird' 'chicken' 'pig' 'cat' 'duck' 'lamb' 'pigeon' 'goat' 'shark' 'sheep' 'cockroach' ...
             'salmon' 'lizard' 'fox' 'falcon' 'tortoise' 'lobster' 'viper' 'hare' 'kitten' 'spider' 'guinea pig' ...
             'slug' 'ant' 'giraffe' 'coyote' 'weasel' 'beaver' 'trout' 'seal' 'python' 'herring' 'quail' 'bear cub' ...
             'canary' 'octopus' 'cicada' 'otter' 'condor' 'turkey' 'buffalo' 'pheasant' 'lioness' 'calf' 'monkey' ...
             'pug' 'impala' 'alpaca' 'goldfish'}'; 
animals = movevars(animals, 'transl', 'Before', 'phon');

% same as above, both frequencies should be > 1/mil
animals_AND = animals(animals.freqfilms2 > 1 & animals.freqlivres > 1,:);

%% 4. Merge of lexique and infra information 

% Remove Phon.-Graph. indexes, not relevant for this study (we start from graphemes)
% Also, keep only the entries relative to names (to skim the matrix)
infra_GrPh = infra(infra.cgram == 'NOM',1:23);

% Selections of words unified again to add linguistic properties. Adds
% together the two matrices (animals and places)
words = vertcat(places, animals);

% Same var name needed to use join function
words.Properties.VariableNames{1} = 'Item';

% matches function finds matches for a string. Here, we find all the rows
% for the selected words. Then join (by itslef it did not work) the two 
% matrixes in one with all the details
infra_sel_words = infra_GrPh(matches(infra_GrPh.Item,table2cell(words(:,1))),:);
words = join(words,infra_sel_words);

%% 5. Compute similarity (TENTETIVE - NOT INFORMATIVE. SKIP)

% skim some details to calculate correlations, only words and their GR-PH associations
words_GP = words(:,[1 18]);

% New table with just the Gr-Ph mappings. One per cell to better work with
% them (probably better way)
vt = {'string','string','string','string','string','string'};
vn = {'assoc_P1','assoc_P2','assoc_P3','assoc_P4','assoc_P5','assoc_P6'};
words_assoc = table('Size',[105 6],'VariableTypes',vt,'VariableNames',vn);

% for each word, splits the associations and store them in
for i=1:size(words_GP,1)
    % temporary stored and placed in a table
    temp = split(words_GP{i,2},'.')'; % splits the string in the single assocations
    words_assoc(i,[1:length(temp)]) = temp; % puts them into the new matrix
end

% NUMBER OF COMMON GP / AVERAGE BETWEEN WORDS (e.g. maison-prison = 2/4.5;
% maison-cin√©ma = 1/5)

% matrix to store the similarity values
sim_matrix = zeros(105);

for i = 1:105 % do it for every entry
    w1 = table2array(words_assoc(i,:)); % first word
    w1_numP = 6 - sum(ismissing(w1(:))); % calculates the total of phonemes for w1 (maximum minus the missing ones)
    for j = 1:105 % compare it to every entry 
        w2 = table2array(words_assoc(j,:)); % second word
        w2_numP = 6 - sum(ismissing(w2(:))); % number of phonemes in w2
        
        % Calculate similarities: look which patterns (GP) of word 1 are
        % present also in w2. Return a 6x1 logical array
        sim = sum(matches(w1(:),w2(:))); 
        avg_GP = mean([w1_numP w2_numP]);  % DOES NOT COMPUTE
        
        % Value is added to the similarity matrix
        sim_matrix(i,j) = sim/avg_GP;
    end
end

clearvars avg_GP w1 w1_numP w2_numP w2 i j temp vn vt sim 

%% 5. Make .xlsx files and save dataset 

% Localizer data
writetable(loc_lex,'preselection_untransl_localizer.xlsx');

% MVPA data, already chosen words and 'full' dataset
writetable(mvpa_6L_lex,'preselection_untransl_mvpa.xlsx');
writetable(words,'preselection_mvpa.xlsx');

% Make a small summary of word selected, for internal use (H-O
% presentation)
writetable(words(:,[1 2 3 8 9 17 18]),'summary_mvpa.xlsx');

% Clear workspace
clearvars infra lex lex_length infra_sel_words 

% Change date accordingly
save('stimuli_initial_selection.mat');
